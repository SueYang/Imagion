{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO\n",
    "\n",
    "- Resize all images to standard size\n",
    "- Add code to convert labels to proper format\n",
    "- Figure out how to do proper testing (code to pair up images randomly, predict their score using neural network, and then compare whether the ordinal match was right using our score)\n",
    "- Figure out how to incoroporate regression output\n",
    "- Rewrite of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 160, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 160, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 80, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 80, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 40, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 20, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# If you want to specify input tensor\n",
    "input_tensor = Input(shape=(160, 160, 3))\n",
    "vgg_model = applications.VGG16(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_tensor=input_tensor)\n",
    "\n",
    "# To see the models' architecture and layer names, run the following\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary that maps layer names to the layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "x = layer_dict['block4_pool'].output\n",
    "\n",
    "# Stacking a new simple convolutional network on top of it    \n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Creating new model. Please note that this is NOT a Sequential() model.\n",
    "from keras.models import Model\n",
    "custom_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "\n",
    "# Make sure that the pre-trained bottom layers are not trainable\n",
    "for layer in custom_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Do not forget to compile it\n",
    "custom_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='rmsprop',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import csv, sqlite3\n",
    "import math\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create dictionary with:\n",
    "Key = filename root\n",
    "Value = score\n",
    "\"\"\"\n",
    "\n",
    "con = sqlite3.connect(\"imagion.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "table_cols = [i[0] for i in cur.execute(\"SELECT * FROM imagion\").description]\n",
    "\n",
    "def get_filenames(): \n",
    "    files_dict = {}\n",
    "    \n",
    "    cur.execute(\"SELECT filename, scale_qsc FROM imagion\")\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for file_, int_score in cur.fetchall():\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "            continue\n",
    "            \n",
    "        count += 1 \n",
    "        \n",
    "        int_score = int_score - 1\n",
    "        \n",
    "        files_dict[file_] = int_score\n",
    "        \n",
    "    return files_dict\n",
    "\n",
    "files_dict = get_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Split training and test images\"\"\"\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "keys = files_dict.keys()\n",
    "split = int(len(files_dict.keys()) * 0.75)\n",
    "\n",
    "random.shuffle(keys)\n",
    "\n",
    "train_keys = keys[:split]\n",
    "test_keys = keys[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l\"\"\"\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "# def get_train_data(chunk, img_row, img_col):\n",
    "#     X_train = []\n",
    "#     Y_train = []\n",
    "    \n",
    "#     try:\n",
    "#         for imgname in chunk:\n",
    "#             Y_train.append(files_dict[imgname])\n",
    "#             filename = 'data_images'+'/'+imgname+'.png'\n",
    "#             img = cv2.imread(filename)\n",
    "#             img = cv2.resize(img,(img_row,img_col))\n",
    "#             X_train.append(img)\n",
    "\n",
    "#         X_train = np.asarray(X_train)\n",
    "#         Y_train = np.asarray(Y_train)\n",
    "        \n",
    "#         return X_train,Y_train\n",
    "\n",
    "#     except:\n",
    "#         X_train=None\n",
    "#         Y_train=None\n",
    "#         return X_train,Y_train\n",
    "\n",
    "def get_train_data(chunk, img_row, img_col):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    \n",
    "    for imgname in chunk:\n",
    "        try:\n",
    "            filename = 'data_images'+'/'+imgname+'.png'\n",
    "            img = cv2.imread(filename)\n",
    "            img = cv2.resize(img,(img_row,img_col))\n",
    "            X_train.append(img)\n",
    "            Y_train.append(files_dict[imgname])\n",
    "        except: \n",
    "            continue\n",
    "    X_train = np.asarray(X_train)\n",
    "    Y_train = np.asarray(Y_train)\n",
    "\n",
    "    return X_train,Y_train\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def get_test_data(chunk, img_row, img_col):\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    \n",
    "    for imgname in chunk:\n",
    "        try:\n",
    "            filename = './data_images'+'/'+imgname+'.png'\n",
    "            img = cv2.imread(filename)\n",
    "            img = cv2.resize(img,(img_row,img_col))\n",
    "            X_test.append(img)\n",
    "            Y_test.append(files_dict[imgname])\n",
    "        except:\n",
    "            continue\n",
    "    X_test = np.asarray(X_test)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "\n",
    "    return X_test,Y_test\n",
    "\n",
    "def getTrainData(chunk,nb_classes,img_rows,img_cols):\n",
    "    X_train,Y_train = get_train_data(chunk,img_rows,img_cols)\n",
    "    if (X_train!=None and Y_train!=None):\n",
    "        X_train/=255\n",
    "    Y_train=np_utils.to_categorical(Y_train, num_classes = 10)\n",
    "    return (X_train,Y_train)\n",
    "\n",
    "def getTestData(chunk,nb_classes,img_rows,img_cols):\n",
    "    X_test,Y_test = get_test_data(chunk,img_rows,img_cols)\n",
    "    if (X_test!=None and Y_test!=None):\n",
    "        X_test/=255\n",
    "    Y_test=np_utils.to_categorical(Y_test, num_classes = 10)\n",
    "    return (X_test,Y_test)\n",
    "\n",
    "def test(model, nb_epoch, spatial_test_data, nb_classes, img_rows, img_cols):\n",
    "    X_test,Y_test = getTestData(test_keys,nb_classes,img_rows,img_cols)\n",
    "    return (X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "('Epoch', 0)\n",
      "----------------------------------------\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haroon_choudery/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:69: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/home/haroon_choudery/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:21: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "30/30 [==============================] - 21s - loss: 15.5808 - acc: 0.0333        \n",
      "32\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 16.1181 - acc: 0.0000e+00    \n",
      "64\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 13.3391 - acc: 0.1724    \n",
      "96\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 18s - loss: 14.8782 - acc: 0.0769    \n",
      "128\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 15.0065 - acc: 0.0690    \n",
      "160\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 21s - loss: 12.3572 - acc: 0.2333    \n",
      "192\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 14.4507 - acc: 0.1034    \n",
      "224\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 19s - loss: 14.9242 - acc: 0.0741    \n",
      "256\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 12.2275 - acc: 0.2414    \n",
      "288\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 23s - loss: 13.0960 - acc: 0.1875    \n",
      "320\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 21s - loss: 14.5063 - acc: 0.1000    \n",
      "352\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 19s - loss: 14.9242 - acc: 0.0741    \n",
      "384\n",
      "Epoch 1/1\n",
      "28/28 [==============================] - 20s - loss: 12.0886 - acc: 0.2500    \n",
      "416\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 22s - loss: 12.7131 - acc: 0.1935    \n",
      "448\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 18s - loss: 14.8782 - acc: 0.0769    \n",
      "480\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 16.1181 - acc: 0.0000e+00    \n",
      "512\n",
      "Epoch 1/1\n",
      "25/25 [==============================] - 18s - loss: 13.5392 - acc: 0.1600    \n",
      "544\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 21s - loss: 14.5063 - acc: 0.1000    \n",
      "576\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 13.8949 - acc: 0.1379    \n",
      "608\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 19s - loss: 15.3580 - acc: 0.0370    \n",
      "640\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 15.5623 - acc: 0.0345    \n",
      "672\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 21s - loss: 15.0436 - acc: 0.0667    \n",
      "704\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 14.4507 - acc: 0.1034    \n",
      "736\n",
      "Epoch 1/1\n",
      "28/28 [==============================] - 20s - loss: 13.2399 - acc: 0.1786    \n",
      "768\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 21s - loss: 15.5808 - acc: 0.0333    \n",
      "800\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 19s - loss: 13.7302 - acc: 0.1481    \n",
      "832\n",
      "Epoch 1/1\n",
      "25/25 [==============================] - 18s - loss: 14.1839 - acc: 0.1200    \n",
      "864\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 12.2275 - acc: 0.2414    \n",
      "896\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 21s - loss: 13.9690 - acc: 0.1333    \n",
      "928\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 19s - loss: 14.9242 - acc: 0.0741    \n",
      "960\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 19s - loss: 14.8782 - acc: 0.0769    \n",
      "992\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 22s - loss: 13.5184 - acc: 0.1613    \n",
      "1024\n",
      "Epoch 1/1\n",
      "28/28 [==============================] - 20s - loss: 14.9668 - acc: 0.0714    \n",
      "1056\n",
      "Epoch 1/1\n",
      "28/28 [==============================] - 20s - loss: 14.3912 - acc: 0.1071    \n",
      "1088\n",
      "Epoch 1/1\n",
      "28/28 [==============================] - 20s - loss: 14.9668 - acc: 0.0714    \n",
      "1120\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 21s - loss: 15.0065 - acc: 0.0690    \n",
      "1152\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 19s - loss: 14.8782 - acc: 0.0769    \n",
      "1184\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 19s - loss: 14.9242 - acc: 0.0741    \n",
      "1216\n",
      "Epoch 1/1\n",
      "24/30 [=======================>......] - ETA: 4s - loss: 14.1033 - acc: 0.1250"
     ]
    }
   ],
   "source": [
    "chunk_size = 10\n",
    "nb_epoch = 50\n",
    "batch_size = 2\n",
    "nb_classes = 10\n",
    "chunk_size = 32\n",
    "img_rows = 160\n",
    "img_cols = 160\n",
    "\n",
    "\n",
    "for e in range(nb_epoch):\n",
    "    print('-'*40)\n",
    "    print('Epoch', e)\n",
    "    print('-'*40)\n",
    "    print(\"Training...\")\n",
    "    instance_count=0\n",
    "\n",
    "\n",
    "    for chunk in chunks(train_keys, chunk_size):\n",
    "        X_chunk,Y_chunk=getTrainData(chunk,nb_classes,img_rows,img_cols)\n",
    "\n",
    "        if (X_chunk!=None and Y_chunk!=None):\n",
    "            #for X_batch, Y_batch in datagen.flow(X_chunk, Y_chunk, batch_size=chunk_size):\n",
    "            loss = custom_model.fit(X_chunk, Y_chunk, verbose=1, batch_size=batch_size, epochs=1)\n",
    "            instance_count+=chunk_size\n",
    "            print instance_count\n",
    "            if instance_count%100==0:\n",
    "                custom_model.save_weights('basic_model.h5',overwrite=True)\n",
    "            \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" SUDO CODE FOR CUSTOM ACCURACY FUNCTION\"\"\"\n",
    "\n",
    "def test_accuracy():\n",
    "    count = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # select two images randomly\n",
    "    \n",
    "    # predict score for each image\n",
    "    \n",
    "    # compare whichever predicted score is higher\n",
    "    \n",
    "    # compare whichever \"score\" is higher\n",
    "    \n",
    "    # check if comparisons match \n",
    "    \n",
    "        # if comparisons match, then accuracy += 1\n",
    "        # if not, then nothing\n",
    "        \n",
    "    # count += 1\n",
    "    \n",
    "    # divide accuracy / count to get final accuracy percentage\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

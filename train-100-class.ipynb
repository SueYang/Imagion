{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO\n",
    "\n",
    "- Delete empty images and add them to clean_dataset folder [DONE]\n",
    "- Figure out how to shuffle by user, rather than by photo, make comparisons within users [DONE]\n",
    "- Figure out how to do proper testing (code to pair up images randomly, predict their score using neural network, and then compare whether the ordinal match was right using our score) [DONE]\n",
    "\n",
    "- Change training code to pull only images from new training set\n",
    "\n",
    "### TO DO LATER\n",
    "- Figure out how to incoroporate regression output\n",
    "- Rewrite of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications, optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv, sqlite3\n",
    "import math\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 98, 98, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 49, 49, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               17334784  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               51813     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 17,452,165\n",
      "Trainable params: 17,452,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# If you want to specify input tensor\n",
    "img_rows = 100\n",
    "img_cols = 100\n",
    "num_classes = 101\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Custom Optimizer\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=1e-6)\n",
    "\n",
    "# Do not forget to compile it\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create dictionary with:\n",
    "Key = filename root\n",
    "Value = score\n",
    "\"\"\"\n",
    "\n",
    "con = sqlite3.connect(\"imagion.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "table_cols = [i[0] for i in cur.execute(\"SELECT * FROM slimscoresclass\").description]\n",
    "\n",
    "def get_filenames(): \n",
    "    files_dict = {}\n",
    "    \n",
    "    cur.execute(\"SELECT filename, class_score FROM slimscoresclass\")\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for file_, score in cur.fetchall():\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "            continue\n",
    "        \n",
    "        files_dict[file_] = score\n",
    "            \n",
    "        count += 1 \n",
    "        \n",
    "    return files_dict\n",
    "\n",
    "files_dict = get_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create dictionary with:\n",
    "Key = alias\n",
    "Value = list of filenames for user\n",
    "\"\"\"\n",
    "\n",
    "DATASET_DIR = 'data_images'\n",
    "\n",
    "def create_user_dict(dataset_dir):\n",
    "    user_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        filename = filename.rsplit('.', 1)[0]\n",
    "        alias = filename.rsplit('_', 1)[0]\n",
    "        \n",
    "        # do not include outliers\n",
    "        if filename not in files_dict.keys():\n",
    "            continue\n",
    "            \n",
    "        if alias not in user_dict:\n",
    "            user_dict[alias] = [filename]\n",
    "        else:\n",
    "            user_dict[alias].append(filename)\n",
    "            \n",
    "    return user_dict\n",
    "\n",
    "user_dict = create_user_dict(DATASET_DIR)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Split training and test images\"\"\"\n",
    "\n",
    "PERCENT_TRAINING = 0.75 \n",
    "\n",
    "random.seed(10)\n",
    "keys = user_dict.keys()\n",
    "\n",
    "split = int(len(user_dict.keys()) * PERCENT_TRAINING)\n",
    "\n",
    "random.shuffle(keys) # revisit this shuffle function\n",
    "\n",
    "train_users = keys[:split]\n",
    "test_users = keys[split:]\n",
    "\n",
    "train_keys = []\n",
    "test_keys = []\n",
    "\n",
    "for user in train_users:\n",
    "    for filename in user_dict[user]:\n",
    "        train_keys.append(filename)\n",
    "        \n",
    "for user in test_users:\n",
    "    for filename in user_dict[user]:\n",
    "        test_keys.append(filename)\n",
    "        \n",
    "random.shuffle(train_keys)\n",
    "random.shuffle(test_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0' '0.1' '0.2' '0.3' '0.4' '0.5' '0.6' '0.7' '0.8' '0.9' '1.0' '1.1'\n",
      " '1.2' '1.3' '1.4' '1.5' '1.6' '1.7' '1.8' '1.9' '10.0' '2.0' '2.1' '2.2'\n",
      " '2.3' '2.4' '2.5' '2.6' '2.7' '2.8' '2.9' '3.0' '3.1' '3.2' '3.3' '3.4'\n",
      " '3.5' '3.6' '3.7' '3.8' '3.9' '4.0' '4.1' '4.2' '4.3' '4.4' '4.5' '4.6'\n",
      " '4.7' '4.8' '4.9' '5.0' '5.1' '5.2' '5.3' '5.4' '5.5' '5.6' '5.7' '5.8'\n",
      " '5.9' '6.0' '6.1' '6.2' '6.3' '6.4' '6.5' '6.6' '6.7' '6.8' '6.9' '7.0'\n",
      " '7.1' '7.2' '7.3' '7.4' '7.5' '7.6' '7.7' '7.8' '7.9' '8.0' '8.1' '8.2'\n",
      " '8.3' '8.4' '8.5' '8.6' '8.7' '8.8' '8.9' '9.0' '9.1' '9.2' '9.3' '9.4'\n",
      " '9.5' '9.6' '9.7' '9.8' '9.9']\n"
     ]
    }
   ],
   "source": [
    "Y = np.arange(0, 10.1, 0.1)\n",
    "Y = [str(num) for num in Y]\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "\n",
    "print encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l\"\"\"\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "def get_train_data(chunk, img_row, img_col):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    \n",
    "    for imgname in chunk:\n",
    "        try:\n",
    "            filename = 'data_images'+'/'+imgname+'.png'\n",
    "            img = cv2.imread(filename)\n",
    "            img = cv2.resize(img,(img_row,img_col))\n",
    "            X_train.append(img)\n",
    "            Y_train.append(str(files_dict[imgname]))\n",
    "        except: \n",
    "            continue\n",
    "    X_train = np.asarray(X_train)\n",
    "    Y_train = np.asarray(Y_train)\n",
    "\n",
    "    return X_train,Y_train\n",
    "    \n",
    "def get_test_data(chunk, img_row, img_col):\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    \n",
    "    for imgname in chunk:\n",
    "        try:\n",
    "            filename = './data_images'+'/'+imgname+'.png'\n",
    "            img = cv2.imread(filename)\n",
    "            img = cv2.resize(img,(img_row,img_col))\n",
    "            X_test.append(img)\n",
    "            Y_test.append(str(files_dict[imgname]))\n",
    "        except:\n",
    "            continue\n",
    "    X_test = np.asarray(X_test)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "\n",
    "    return X_test,Y_test\n",
    "\n",
    "def getTrainData(chunk,img_rows,img_cols):\n",
    "    X_train,Y_train = get_train_data(chunk,img_rows,img_cols)\n",
    "    if (X_train is not None and Y_train is not None):\n",
    "        X_train/=255\n",
    "        encoded_Y = encoder.transform(Y_train)\n",
    "        Y_train=np_utils.to_categorical(encoded_Y, num_classes=101)\n",
    "    return (X_train,Y_train)\n",
    "\n",
    "def getTestData(chunk,img_rows,img_cols):\n",
    "    X_test,Y_test = get_test_data(chunk,img_rows,img_cols)\n",
    "    if (X_test is not None and Y_test is not None):\n",
    "        X_test/=255\n",
    "        encoded_Y = encoder.transform(Y_test)\n",
    "        Y_test=np_utils.to_categorical(encoded_Y, num_classes=101)\n",
    "    return (X_test,Y_test)\n",
    "\n",
    "def test(model, nb_epoch, spatial_test_data, img_rows, img_cols):\n",
    "    X_test,Y_test = getTestData(test_keys,img_rows,img_cols)\n",
    "    return (X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "nb_epoch = 100\n",
    "batch_size = 2\n",
    "chunk_size = 32\n",
    "img_rows = 100\n",
    "img_cols = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epoch 0\n",
      "----------------------------------------\n",
      "Training...\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 32\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0625     \n",
      "Instance Count: 64\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 96\n",
      "(31, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "31/31 [==============================] - 2s - loss: 0.0098 - acc: 0.0323     \n",
      "Instance Count: 128\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 160\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 192\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 224\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 256\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 288\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 320\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 352\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 384\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 416\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 448\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 480\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 512\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 544\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 576\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 608\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312       \n",
      "Instance Count: 640\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 672\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 704\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 736\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 768\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 800\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 832\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 864\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 896\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 928\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 960\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 992\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1024\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 1056\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1088\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 1120\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0625     \n",
      "Instance Count: 1152\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1184\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1216\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1248\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1280\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1312\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1344\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1376\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 1408\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312        \n",
      "Instance Count: 1440\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 1472\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312         \n",
      "Instance Count: 1504\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1536\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1568\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312      \n",
      "Instance Count: 1600\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1632\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 1664\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1696\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 1728\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1760\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1792\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1824\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1856\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 1888\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0938     \n",
      "Instance Count: 1920\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 1952\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 1984\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2016\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2048\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312         \n",
      "Instance Count: 2080\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2112\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 2144\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2176\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2208\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2240\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0625     \n",
      "Instance Count: 2272\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2304\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2336\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2368\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 2400\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2432\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2464\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2496\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2528\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2560\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     - ETA: 2s - loss: 0.0098 - acc\n",
      "Instance Count: 2592\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2624\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 2656\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2688\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     - ETA: 0s - loss: 0.0098 - acc: 0.0000e+\n",
      "Instance Count: 2720\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2752\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2784\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 2816\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2848\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2880\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2912\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2944\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 2976\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3008\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3040\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 3072\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3104\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3136\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3168\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3200\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3232\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3264\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0625     \n",
      "Instance Count: 3296\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3328\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 3360\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 3392\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3424\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3456\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3488\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 3520\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3552\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3584\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0312     \n",
      "Instance Count: 3616\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 2s - loss: 0.0098 - acc: 0.0000e+00     \n",
      "Instance Count: 3648\n",
      "(32, 101)\n",
      "\n",
      "Epoch 1/1\n",
      " 4/32 [==>...........................] - ETA: 2s - loss: 0.0098 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "for e in range(nb_epoch):\n",
    "    print('-'*40)\n",
    "    print 'Epoch', e\n",
    "    print('-'*40)\n",
    "    print \"Training...\"\n",
    "    instance_count=0\n",
    "\n",
    "\n",
    "    for chunk in chunks(train_keys, chunk_size):\n",
    "        X_chunk,Y_chunk=getTrainData(chunk,img_rows,img_cols)\n",
    "\n",
    "        if (X_chunk is not None and Y_chunk is not None):\n",
    "            loss = model.fit(X_chunk, Y_chunk, verbose=1, batch_size=batch_size, epochs=num_epochs)\n",
    "            instance_count+=chunk_size\n",
    "            \n",
    "            print \"Instance Count:\", instance_count\n",
    "            \n",
    "            if instance_count%64==0:\n",
    "                model.save_weights('model_class.h5',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = 'model_class.h5'\n",
    "\n",
    "if weights_path:\n",
    "    model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" SUDO CODE FOR CUSTOM ACCURACY FUNCTION\"\"\"\n",
    "\n",
    "DATASET_DIR = 'data_images'\n",
    "\n",
    "def test_accuracy():\n",
    "    count = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for user in test_users:\n",
    "        user_imgs = user_dict[user]\n",
    "        \n",
    "        if len(user_imgs) > 1:\n",
    "           # get two elements from shuffled dictionary\n",
    "            element1 = user_imgs.pop(0)\n",
    "            element2 = user_imgs.pop(1)\n",
    "            \n",
    "            # read images\n",
    "            img1 = cv2.imread(os.path.join(DATASET_DIR, element1+'.png'))\n",
    "            img2 = cv2.imread(os.path.join(DATASET_DIR, element2+'.png'))\n",
    "            \n",
    "            #resize images\n",
    "            img1 = cv2.resize(img1,(img_rows,img_cols))\n",
    "            img2 = cv2.resize(img2,(img_rows,img_cols))\n",
    "            \n",
    "            # expand dimension\n",
    "            img1 = np.expand_dims(img1, axis=0)\n",
    "            img2 = np.expand_dims(img2, axis=0)\n",
    "        \n",
    "            # predict score for each image\n",
    "            predict1 = np.argmax(model.predict(img1))\n",
    "            predict2 = np.argmax(model.predict(img2))\n",
    "            \n",
    "            # compare whichever predicted score is higher\n",
    "            \n",
    "            # comparison dict\n",
    "            if predict1 > predict2:\n",
    "                max_predict = 'a'\n",
    "            elif predict1 < predict2:\n",
    "                max_predict = 'b'\n",
    "            else:\n",
    "                max_predict = 'equal'\n",
    "            \n",
    "            # compare whichever \"score\" is higher\n",
    "            if files_dict[element1] > files_dict[element2]:\n",
    "                max_actual = 'a'\n",
    "            elif files_dict[element1] < files_dict[element2]:\n",
    "                max_actual = 'b'\n",
    "            else:\n",
    "                max_actual = 'equal'\n",
    "\n",
    "            # check if comparisons match \n",
    "            if max_predict == max_actual:\n",
    "                accuracy +=1\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "            print max_predict\n",
    "            print max_actual\n",
    "            print max_predict == max_actual\n",
    "            print '\\n'\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    accuracy_per = accuracy / count\n",
    "    \n",
    "    print count, \"comparisons made\"\n",
    "    print \"Accuracy score is:\", accuracy_per\n",
    "    \n",
    "    return\n",
    "\n",
    "test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.289618\n",
      "Score is 0.501007\n",
      "Score is 0.707981\n",
      "Score is 0.501007\n",
      "Score is 0.501007\n",
      "Score is 0.501007\n",
      "Score is 0.501007\n",
      "Score is 0.501007\n",
      "Score is 0.14877\n",
      "Score is 0.501007\n",
      "Score is 0.759573\n",
      "Score is 0.501007\n",
      "Score is 0.501007\n",
      "Score is 0.548562\n"
     ]
    }
   ],
   "source": [
    "# 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16\n",
    "img_names = ['xostylistxo_1',\n",
    "             'xostylistxo_2', \n",
    "             'xostylistxo_3', \n",
    "             'xostylistxo_5', \n",
    "             'xostylistxo_6', \n",
    "             'xostylistxo_7', \n",
    "             'xostylistxo_9', \n",
    "             'xostylistxo_10', \n",
    "             'xostylistxo_11', \n",
    "             'xostylistxo_12', \n",
    "             'xostylistxo_13', \n",
    "             'xostylistxo_14',\n",
    "             'xostylistxo_15',\n",
    "             'xostylistxo_16']\n",
    "             \n",
    "for img_name in img_names:\n",
    "    img = cv2.imread('data_images/'+img_name+'.png')\n",
    "    img = cv2.resize(img,(160,160))\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    print \"Score is\", model.predict(img)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.489362\n"
     ]
    }
   ],
   "source": [
    "img2 = cv2.imread('data_images/'+img_name+'.png')\n",
    "img2 = cv2.resize(img2,(160,160))\n",
    "img2 = img2/255\n",
    "img2 = np.expand_dims(img2, axis=0)\n",
    "\n",
    "print \"Score is\", model.predict(img2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 8.3\n",
      "Score is 8.3\n",
      "Score is 1.0\n",
      "Score is 1.0\n",
      "Score is 9.4\n",
      "Score is 0.4\n",
      "Score is 1.0\n",
      "Score is 0.4\n",
      "Score is 0.4\n",
      "Score is 1.0\n",
      "Score is 1.8\n",
      "Score is 8.3\n",
      "Score is 8.2\n",
      "Score is 9.0\n",
      "Score is 8.3\n",
      "Score is 6.6\n",
      "Score is 8.6\n",
      "Score is 1.8\n",
      "Score is 5.0\n",
      "Score is 0.4\n",
      "Score is 4.8\n",
      "Score is 1.8\n",
      "Score is 5.0\n",
      "Score is 2.3\n",
      "Score is 6.7\n",
      "Score is 0.4\n",
      "Score is 4.1\n",
      "Score is 1.8\n",
      "Score is 1.8\n",
      "Score is 0.8\n",
      "Score is 0.4\n",
      "Score is 0.8\n",
      "Score is 1.0\n",
      "Score is 0.4\n",
      "Score is 0.4\n",
      "Score is 1.8\n",
      "Score is 0.4\n",
      "Score is 1.0\n",
      "Score is 0.4\n",
      "Score is 0.4\n",
      "Score is 0.4\n",
      "Score is 7.4\n",
      "Score is 1.8\n",
      "Score is 0.8\n",
      "Score is 0.4\n",
      "Score is 1.8\n",
      "Score is 1.5\n",
      "Score is 0.4\n",
      "Score is 6.6\n",
      "Score is 4.9\n",
      "Score is 0.8\n",
      "Score is 0.4\n",
      "Score is 2.3\n",
      "Score is 0.8\n",
      "Score is 0.4\n",
      "Score is 0.4\n",
      "Score is 5.0\n",
      "Score is 8.3\n",
      "Score is 8.3\n",
      "Score is 5.6\n",
      "Score is 9.4\n",
      "Score is 0.4\n",
      "Score is 0.4\n",
      "Score is 0.4\n",
      "Score is 8.3\n",
      "Score is 0.4\n",
      "Score is 0.0\n",
      "Score is 0.4\n",
      "Score is 4.8\n",
      "Score is 1.8\n",
      "Score is 7.5\n",
      "Score is 8.2\n",
      "Score is 1.8\n",
      "Score is 1.8\n",
      "Score is 0.0\n",
      "Score is 0.4\n",
      "Score is 4.1\n",
      "Score is 0.4\n",
      "Score is 1.0\n",
      "Score is 0.8\n",
      "Score is 0.4\n",
      "Score is 0.4\n",
      "Score is 8.3\n",
      "Score is 8.3\n",
      "Score is 5.0\n",
      "Score is 8.3\n",
      "Score is 4.8\n",
      "Score is 0.4\n",
      "Score is 1.0\n",
      "Score is 0.4\n",
      "Score is 4.8\n",
      "Score is 8.3\n",
      "Score is 1.8\n",
      "Score is 8.3\n",
      "Score is 0.8\n",
      "Score is 1.0\n",
      "Score is 8.6\n",
      "Score is 4.8\n",
      "Score is 1.8\n",
      "Score is 5.9\n"
     ]
    }
   ],
   "source": [
    "for img_name in test_keys[:100]:\n",
    "    img = cv2.imread('data_images/'+img_name+'.png')\n",
    "    img = cv2.resize(img,(100,100))\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    predictions = model.predict(img)\n",
    "    top = np.argmax(predictions, axis=1)\n",
    "    pred = encoder.inverse_transform([top])\n",
    "    \n",
    "    print \"Score is\", pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
